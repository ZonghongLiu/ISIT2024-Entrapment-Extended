{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61199820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eed611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_LRdata(w, sigX, n, muX = None):\n",
    "    # synthesize Linear regression data with given parameter (w,b), \n",
    "    # Variance of X and \\epsilon, number of samples n.\n",
    "    # Output the torch tensor data X, y\n",
    "    if w.dtype != torch.float64:\n",
    "        w = w.to(torch.float64)\n",
    "    #print(w.dtype)\n",
    "    if muX == None:\n",
    "        muX = torch.zeros(len(w))\n",
    "\n",
    "    X = np.random.multivariate_normal(mean=muX, cov = sigX*np.identity(len(w)), size=n)\n",
    "    for i in range(n):\n",
    "        X[i, 0] = 1.\n",
    "    X = torch.tensor(X)\n",
    "    #print(X)\n",
    "    #print(X,w)\n",
    "    y = torch.matmul(X, w) \n",
    "    #y += torch.normal(0, sige, y.shape)\n",
    "    return X, y.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee303b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the adjacency matrix\n",
    "def ring(n):\n",
    "    A = np.zeros((n, n))\n",
    "    for i in range(n-1):\n",
    "        A[i, i+1] = 1\n",
    "        A[i+1, i] = 1\n",
    "    A[0, n-1] = 1\n",
    "    A[n-1, 0] = 1\n",
    "    return A\n",
    "\n",
    "def erdos_renyi(n, p):\n",
    "    # Generate an Erdős-Rényi graph with parameters (n, p)\n",
    "    er_graph = nx.erdos_renyi_graph(n, p)\n",
    "    \n",
    "    # Convert the graph to an adjacency matrix\n",
    "    adjacency_matrix = nx.to_numpy_matrix(er_graph)\n",
    "    \n",
    "    return adjacency_matrix\n",
    "\n",
    "def watts_strogatz(n, k, p):\n",
    "    # Generate a Watts-Strogatz graph with parameters (n, k, p)\n",
    "    ws_graph = nx.watts_strogatz_graph(n, k, p)\n",
    "    \n",
    "    # Convert the graph to an adjacency matrix\n",
    "    adjacency_matrix = nx.to_numpy_matrix(ws_graph)\n",
    "    \n",
    "    return adjacency_matrix\n",
    "\n",
    "def grid(rows, cols):\n",
    "    total_nodes = rows * cols\n",
    "    adjacency_matrix = np.zeros((total_nodes, total_nodes), dtype=int)\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            node = i * cols + j\n",
    "            \n",
    "            if i > 0:\n",
    "                adjacency_matrix[node, node - cols] = 1  # Upper neighbor\n",
    "            if i < rows - 1:\n",
    "                adjacency_matrix[node, node + cols] = 1  # Lower neighbor\n",
    "            if j > 0:\n",
    "                adjacency_matrix[node, node - 1] = 1      # Left neighbor\n",
    "            if j < cols - 1:\n",
    "                adjacency_matrix[node, node + 1] = 1      # Right neighbor\n",
    "                \n",
    "    return adjacency_matrix\n",
    "\n",
    "def twoblock(n1, n2, p_high, p_low):\n",
    "    n = n1 + n2  # Total number of vertices\n",
    "    \n",
    "    # Create an empty adjacency matrix\n",
    "    adjacency_matrix = np.zeros((n, n), dtype=int)\n",
    "    \n",
    "    # Create the first community\n",
    "    for i in range(n1):\n",
    "        for j in range(i + 1, n1):\n",
    "            if np.random.rand() < p_high:\n",
    "                adjacency_matrix[i, j] = 1\n",
    "                adjacency_matrix[j, i] = 1\n",
    "    \n",
    "    # Create the second community\n",
    "    for i in range(n1, n1 + n2):\n",
    "        for j in range(i + 1, n1 + n2):\n",
    "            if np.random.rand() < p_high:\n",
    "                adjacency_matrix[i, j] = 1\n",
    "                adjacency_matrix[j, i] = 1\n",
    "    \n",
    "    # Connect between communities\n",
    "    for i in range(n1):\n",
    "        for j in range(n1, n):\n",
    "            if np.random.rand() < p_low:\n",
    "                adjacency_matrix[i, j] = 1\n",
    "                adjacency_matrix[j, i] = 1\n",
    "                    \n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2459f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Utils\n",
    "def linreg(X, w):\n",
    "    return(torch.matmul(X, w))\n",
    "    \n",
    "def mseloss(y, y_hat, l):\n",
    "    return((y_hat - y.reshape(y_hat.shape))**2/(2*l))\n",
    "\n",
    "#def sgd(params, lr, weight = 1):  \n",
    "#    with torch.no_grad():\n",
    "#        param -= lr * weight * param.grad\n",
    "#        param.grad.zero_()\n",
    "        \n",
    "def MH(G):\n",
    "    # Uniform via MH\n",
    "    n = G.shape[0]\n",
    "    deg = np.zeros(n)\n",
    "    for k in range(n):\n",
    "        deg[k] = G[k, :].sum()\n",
    "    Pdeg=np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if G[i,j] == 1 and i != j:\n",
    "                Pdeg[i,j] = np.minimum(1., (deg[i])/(deg[j]))/deg[i]\n",
    "        Pdeg[i, i] = np.maximum(0, 1 - np.sum(Pdeg[i, :]))\n",
    "    return Pdeg\n",
    "\n",
    "def MHI(G, X):\n",
    "    # Importance Sampling via MH\n",
    "    n = X.shape[0]\n",
    "    deg = [np.sum(G[i,:]) for i in range(n)]\n",
    "    #print(deg)\n",
    "    Lip = [np.linalg.norm(X[i,:]) for i in range(n)]\n",
    "    Lip = np.array(Lip)**2\n",
    "    plip=Lip/np.sum(Lip)\n",
    "    Plip=np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if G[i,j] == 1 and i != j:\n",
    "                Plip[i,j] = np.minimum(1., deg[i]*Lip[j]/(deg[j]*Lip[i]))/deg[i]\n",
    "        Plip[i, i] = np.maximum(0,1 - np.sum(Plip[i, :]))\n",
    "    return Plip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7faa69e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jump matrix\n",
    "def GtoP(G):\n",
    "    G = np.array(G, dtype = float)\n",
    "    for i in range(G.shape[0]):\n",
    "        w = np.sum(G[i, :])\n",
    "        #print(w)\n",
    "        G[i, :] = G[i, :]/w\n",
    "    return G\n",
    "\n",
    "def truncateGeom(p, i, r):\n",
    "    pd = p * (1 - p) ** (i) / (1 - ( 1 - p ) ** (r))\n",
    "    return pd\n",
    "\n",
    "def Kth_neighbor(G, k, p):\n",
    "    GK = [G]\n",
    "    P = GtoP(GK[0]) * truncateGeom(p, 0, k)\n",
    "    for i in range(k):\n",
    "        GK.append(GK[i]@G)\n",
    "    for i in range(k-1):\n",
    "        P += GtoP(GK[i+1]) * truncateGeom(p, i+1, k)\n",
    "    return P\n",
    "\n",
    "def TruncGeom(pd, r):\n",
    "    ber = np.random.uniform()\n",
    "    prob_dist = pd/(1-(1-pd)**r)\n",
    "    #print(prob_dist)\n",
    "    d = 1\n",
    "    while ber > prob_dist:\n",
    "        d += 1\n",
    "        prob_dist += pd*(1-pd)**(d-1)/(1-(1-pd)**r)\n",
    "        #print(prob_dist)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4df0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main class\n",
    "class RWnode:\n",
    "    def __init__(self, X, y, W1, W2, init_model, pi, index ):\n",
    "        self.index = index\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.W = {'Uniform':W1, 'Importance':W2}\n",
    "        self.neighbors = []\n",
    "        self.model = init_model\n",
    "        self.loss = []\n",
    "        self.pi = pi\n",
    "        self.index = index\n",
    "        \n",
    "        \n",
    "        #print(self.W)\n",
    "        \n",
    "    def localSGD(self, gamma, Xtrain, ytrain, weight = 1):\n",
    "        l = mseloss(self.y, linreg(self.X, self.model), l = 1)\n",
    "        l.backward()\n",
    "        model =  self.model - gamma * self.model.grad / weight\n",
    "        self.model = model.clone().detach().requires_grad_(True)\n",
    "        '''with torch.no_grad():  \n",
    "            n = len(ytrain)\n",
    "            train_l = mseloss(ytrain, linreg(Xtrain, self.model), l = n)\n",
    "            #print(train_l.mean())\n",
    "            self.loss.append(train_l.mean())'''\n",
    "\n",
    "class RW_model:\n",
    "    def __init__(self, G, X, y, k = None):\n",
    "        if k == None:\n",
    "            print('No jump.')\n",
    "            #return\n",
    "        else:\n",
    "            print(f'Levy jump {k}')\n",
    "            self.Kth_P = self.__Kth_neighbor(G, k)\n",
    "        self.n = X.shape[0]\n",
    "        Lip = [np.linalg.norm(X[i,:]) for i in range(self.n)]\n",
    "        Lip = np.array(Lip)**2\n",
    "        plip=Lip/np.sum(Lip)\n",
    "        self.lip = torch.tensor(plip)\n",
    "        self.__initialization(G, X, y,  plip)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.loss = []\n",
    "        #self.loss_communication = []\n",
    "        self.current = self.nodes[0]\n",
    "        self.updates = [0]\n",
    "        self.communication = [0]\n",
    "        \n",
    "    def __Kth_neighbor(self, G, k):\n",
    "        GK = [G]\n",
    "        P = [GtoP(GK[0])] \n",
    "        for i in range(k-1):\n",
    "            GK.append(GK[i]@G)\n",
    "        for i in range(k-1):\n",
    "            P.append(GtoP(GK[i+1]))\n",
    "        return P\n",
    "    \n",
    "    def __GtoP(self, G):\n",
    "        G = np.array(G, dtype = float)\n",
    "        for i in range(G.shape[0]):\n",
    "            w = np.sum(G[i, :])\n",
    "        #print(w)\n",
    "            G[i, :] = G[i, :]/w\n",
    "        return G\n",
    "        \n",
    "        \n",
    "    def __initialization(self, G, X, y, plip):\n",
    "        (n, p) = X.shape\n",
    "        W1 = MH(G)\n",
    "        W2 = MHI(G, X)\n",
    "        initial_model = torch.tensor(np.random.normal(0, 1, p))\n",
    "        self.nodes = [RWnode(X[i, :], y[i], W1[i, :], W2[i, :],  initial_model.detach().clone().requires_grad_(True),  plip[i], i) for i in range(n)]\n",
    "        for node_ind in range(n):\n",
    "            for neighbor_ind in range(n):\n",
    "                if G[node_ind, neighbor_ind] == 1:\n",
    "                    Node = self.nodes[node_ind]\n",
    "                    Node.neighbors.append(self.nodes[neighbor_ind])\n",
    "                    \n",
    "    def re_init(self, model):\n",
    "        for node in self.nodes:\n",
    "            node.model = model\n",
    "                    \n",
    "    def optimize(self, gamma = 0.01, jump = None, mh = 'Importance'):\n",
    "        node = self.current\n",
    "        if mh == 'Importance':\n",
    "            node.localSGD(gamma, self.X, self.y, weight = node.pi * self.n)\n",
    "        else:\n",
    "            node.localSGD(gamma, self.X, self.y)\n",
    "        self.loss.append(self.cal_loss())\n",
    "        if jump == None:\n",
    "            nextnode = np.random.choice(self.nodes, size = 1, p = node.W[mh])[0]\n",
    "            if nextnode != self.current:\n",
    "            #print('2')\n",
    "            #    self.communication.append(self.communication[-1] + 1)\n",
    "                self.commute = True\n",
    "            else:\n",
    "            #print('1')\n",
    "                #self.communication.append(self.communication[-1])\n",
    "                self.commute = False\n",
    "        else:\n",
    "            nextnode = np.random.choice(self.nodes, size = 1, p = self.Kth_P[int(jump)-1][node.index])[0]\n",
    "            #for _ in range(jump):\n",
    "            #    self.communication.append(self.communication[-1] + 1)\n",
    "            self.commute = True\n",
    "        \n",
    "        \n",
    "        self.updates.append(self.updates[-1] + 1)\n",
    "        \n",
    "        # pass the model to the next node\n",
    "        nextnode.model = node.model.clone().detach().requires_grad_(True)\n",
    "        self.current = nextnode\n",
    "        #optimize\n",
    "    \n",
    "    def cal_loss(self):\n",
    "        with torch.no_grad():  \n",
    "            n = len(self.y)\n",
    "            train_l = mseloss(self.y, linreg(self.X, self.current.model), l = n)\n",
    "            #print(train_l.mean())\n",
    "        return train_l.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e49fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeloss_mh(Test1, numpath, maxstep, cut, gamma, init, mh = 'Importance'):\n",
    "    Loss_communication = []\n",
    "    Loss_update = []\n",
    "    for _ in range(numpath):\n",
    "        initialmodel = init.clone().detach().requires_grad_(True)\n",
    "        Test1.re_init(initialmodel)\n",
    "        Test1.current = Test1.nodes[-1]\n",
    "        loss_communication = [0]\n",
    "        loss_update = [0]\n",
    "        for i in range(maxstep):\n",
    "            Test1.optimize(gamma, jump = None, mh = mh)\n",
    "            current_loss = Test1.cal_loss()\n",
    "            loss_update.append(current_loss)\n",
    "            if Test1.commute:\n",
    "                loss_communication.append(current_loss)\n",
    "            else:\n",
    "                loss_communication[-1] = current_loss\n",
    "        Loss_update.append(loss_update)\n",
    "        Loss_communication.append(loss_communication)\n",
    "    #print(len(Loss_communication[0]), len(Loss_communication[1]))\n",
    "    #Loss_update = np.array(Loss_update)\n",
    "    #print(Loss_update.shape)\n",
    "    #Loss_communication = np.array(Loss_communication)\n",
    "    #print(Loss_communication.shape)\n",
    "    return Loss_update,  Loss_communication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2297ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the loss per iteration\n",
    "def computeloss_jump(Test1, numpath, maxstep, cut, pj, pd, r, gamma, init):\n",
    "    #initialmodel = Test1.nodes[0].model.clone().detach().requires_grad_(True)\n",
    "    Loss_communication = []\n",
    "    Loss_update = []\n",
    "    for _ in range(numpath):\n",
    "        initialmodel = init.clone().detach().requires_grad_(True)\n",
    "        Test1.re_init(initialmodel)\n",
    "        Test1.current = Test1.nodes[-1]\n",
    "        loss_communication = [0]\n",
    "        loss_update = [0]\n",
    "        for i in range(maxstep):\n",
    "            if np.random.binomial(1, pj):\n",
    "                Test1.optimize(gamma)\n",
    "                current_loss = Test1.cal_loss()\n",
    "                loss_update.append(current_loss)\n",
    "                if Test1.commute:\n",
    "                    loss_communication.append(current_loss)\n",
    "                else:\n",
    "                    loss_communication[-1] = current_loss\n",
    "            else:\n",
    "                d = TruncGeom(pd, r)\n",
    "                Test1.optimize(gamma, jump = d)\n",
    "                current_loss = Test1.cal_loss()\n",
    "                loss_update.append(current_loss)\n",
    "                for _ in range(d):\n",
    "                    loss_communication.append(current_loss)\n",
    "        Loss_update.append(loss_update[:cut])\n",
    "        Loss_communication.append(loss_communication[:cut])\n",
    "    print(len(Loss_communication[0]), len(Loss_communication[1]))\n",
    "    Loss_update = np.array(Loss_update) \n",
    "    Loss_communication = np.array(Loss_communication) \n",
    "    return np.mean(Loss_update ,axis=0), np.mean(Loss_communication ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3e12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_is, lu_is = computeloss_mh(RW2, 50, 200000, 30000, init = initialmodel, gamma=0.01 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
